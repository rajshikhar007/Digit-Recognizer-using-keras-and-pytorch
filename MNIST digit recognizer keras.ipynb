{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/train.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n",
      "/kaggle/input/digit-recognizer/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPool2D, BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_file='/kaggle/input/digit-recognizer/test.csv'\n",
    "train_file='/kaggle/input/digit-recognizer/train.csv'\n",
    "sub_file='/kaggle/input/digit-recognizer/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.read_csv(sub_file)\n",
    "train =pd.read_csv(train_file)\n",
    "test=pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data  (42000, 785)\n",
      "Shape of test data (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of train data ',train.shape)\n",
    "print('Shape of test data',test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns[train.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns[test.isnull().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no missing values in the train and test dataset. So we can safely go ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.3 Count for each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print data histogram\n",
    "g = sns.countplot(train.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have similar counts for the 10 digits.No imbalanced Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Target label and Reshape training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows=28\n",
    "img_cols=28\n",
    "num_classes=10\n",
    "\n",
    "def prep_data(data):\n",
    "    num_images=data.shape[0]\n",
    "    \n",
    "    out_y = keras.utils.to_categorical(data.label, 10)  # Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "    \n",
    "    x = data.drop(['label'],axis=1)   \n",
    "    \n",
    "    x_train = np.array(x)   #first we have to convert into array so to use .reshape function\n",
    "    out_x=x_train.reshape(-1, img_rows, img_cols, 1)   #Reshaping it into tensor\n",
    "    \n",
    "    #we can directly use like this without converting it into arrays\n",
    "    #out_x = x.values.reshape(-1, img_rows, img_cols, 1) \n",
    "    \n",
    "    out_x = out_x / 255   #Normalisation\n",
    "    return out_x, out_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prep_data(data):\n",
    "    x_test = np.array(data)\n",
    "\n",
    "    out_x=x_test.reshape(-1, img_rows, img_cols, 1)   #Reshaping it into tensor\n",
    "    #out_x = data.values.reshape(-1, img_rows, img_cols, 1)\n",
    "    out_x = out_x / 255\n",
    "    return out_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train=prep_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=test_prep_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.4 Plot Sample images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Test print a digit\n",
    "h = plt.imshow(x_train[11][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to predict & label the final predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(model,test):\n",
    "    y_test=model.predict(test)\n",
    "    y_max = np.argmax(y_test,axis = 1)\n",
    "    sub['Label'] = y_max\n",
    "    return sub\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* # First Convolutional basic model(val accuracy = 0.9832 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cnn_model_a():\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(20, kernel_size=(3, 3),\n",
    "#                  activation='relu',\n",
    "#                  input_shape=(img_rows, img_cols, 1)))\n",
    "#     model.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))\n",
    "#     model.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#     model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "#     return model\n",
    "# model_a=cnn_model_a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_a.fit(x_train, y_train,\n",
    "#           batch_size=128,\n",
    "#           epochs=3,\n",
    "#           validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second model with deep layer(accuracy test=0.9935)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               295424    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 547,658\n",
      "Trainable params: 547,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def cnn_model_b():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (28,28,1)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "  #  model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.20))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (28,28,1)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.20))\n",
    "    \n",
    "    \n",
    "  \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "   # model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.20))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation = \"relu\"))\n",
    "    model.add(Dropout(0.20))\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    model.add(Dropout(0.20))\n",
    "    model.add(Dense(10, activation = \"softmax\"))\n",
    "    # optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile( optimizer='adam' , loss = keras.losses.categorical_crossentropy, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "model_b=cnn_model_b()\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print out model look\n",
    "from keras.utils import plot_model\n",
    "plot_model(model_b, to_file='model_b.png', show_shapes=True, show_layer_names=True)\n",
    "from IPython.display import Image\n",
    "Image(\"model_b.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/30\n",
      "33600/33600 [==============================] - 7s 206us/sample - loss: 0.4871 - accuracy: 0.8363 - val_loss: 0.0723 - val_accuracy: 0.9773\n",
      "Epoch 2/30\n",
      "33600/33600 [==============================] - 3s 78us/sample - loss: 0.0951 - accuracy: 0.9717 - val_loss: 0.0550 - val_accuracy: 0.9825\n",
      "Epoch 3/30\n",
      "33600/33600 [==============================] - 3s 78us/sample - loss: 0.0651 - accuracy: 0.9800 - val_loss: 0.0480 - val_accuracy: 0.9850\n",
      "Epoch 4/30\n",
      "33600/33600 [==============================] - 3s 81us/sample - loss: 0.0552 - accuracy: 0.9831 - val_loss: 0.0352 - val_accuracy: 0.9888\n",
      "Epoch 5/30\n",
      "33600/33600 [==============================] - 3s 78us/sample - loss: 0.0420 - accuracy: 0.9880 - val_loss: 0.0307 - val_accuracy: 0.9910\n",
      "Epoch 6/30\n",
      "33600/33600 [==============================] - 3s 79us/sample - loss: 0.0337 - accuracy: 0.9898 - val_loss: 0.0351 - val_accuracy: 0.9902\n",
      "Epoch 7/30\n",
      "33600/33600 [==============================] - 3s 78us/sample - loss: 0.0341 - accuracy: 0.9901 - val_loss: 0.0289 - val_accuracy: 0.9921\n",
      "Epoch 8/30\n",
      "33600/33600 [==============================] - 3s 84us/sample - loss: 0.0279 - accuracy: 0.9914 - val_loss: 0.0261 - val_accuracy: 0.9931\n",
      "Epoch 9/30\n",
      "33600/33600 [==============================] - 3s 80us/sample - loss: 0.0296 - accuracy: 0.9905 - val_loss: 0.0315 - val_accuracy: 0.9912\n",
      "Epoch 10/30\n",
      "33600/33600 [==============================] - 3s 82us/sample - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.0289 - val_accuracy: 0.9919\n",
      "Epoch 11/30\n",
      "33600/33600 [==============================] - 3s 80us/sample - loss: 0.0225 - accuracy: 0.9928 - val_loss: 0.0310 - val_accuracy: 0.9923\n",
      "Epoch 12/30\n",
      "33600/33600 [==============================] - 3s 79us/sample - loss: 0.0221 - accuracy: 0.9931 - val_loss: 0.0386 - val_accuracy: 0.9895\n",
      "Epoch 13/30\n",
      "33600/33600 [==============================] - 3s 79us/sample - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0300 - val_accuracy: 0.9932\n",
      "Epoch 14/30\n",
      "33600/33600 [==============================] - 3s 78us/sample - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.0291 - val_accuracy: 0.9931\n",
      "Epoch 15/30\n",
      "33600/33600 [==============================] - 3s 77us/sample - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.0288 - val_accuracy: 0.9942\n",
      "Epoch 16/30\n",
      "33600/33600 [==============================] - 3s 82us/sample - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.0285 - val_accuracy: 0.9921\n",
      "Epoch 17/30\n",
      "33600/33600 [==============================] - 3s 78us/sample - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.0296 - val_accuracy: 0.9931\n",
      "Epoch 18/30\n",
      "33600/33600 [==============================] - 3s 77us/sample - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0276 - val_accuracy: 0.9933\n",
      "Epoch 19/30\n",
      "33600/33600 [==============================] - 3s 78us/sample - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0256 - val_accuracy: 0.9940\n",
      "Epoch 20/30\n",
      "33600/33600 [==============================] - 3s 80us/sample - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0288 - val_accuracy: 0.9929\n",
      "Epoch 21/30\n",
      "33600/33600 [==============================] - 3s 78us/sample - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0309 - val_accuracy: 0.9926\n",
      "Epoch 22/30\n",
      "33600/33600 [==============================] - 3s 78us/sample - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0325 - val_accuracy: 0.9927\n",
      "Epoch 23/30\n",
      "33600/33600 [==============================] - 3s 79us/sample - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0348 - val_accuracy: 0.9929\n",
      "Epoch 24/30\n",
      "33600/33600 [==============================] - 3s 80us/sample - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0353 - val_accuracy: 0.9926\n",
      "Epoch 25/30\n",
      "33600/33600 [==============================] - 3s 78us/sample - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.0328 - val_accuracy: 0.9938\n",
      "Epoch 26/30\n",
      "33600/33600 [==============================] - 3s 77us/sample - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.0296 - val_accuracy: 0.9936\n",
      "Epoch 27/30\n",
      "33600/33600 [==============================] - 3s 78us/sample - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.0290 - val_accuracy: 0.9924\n",
      "Epoch 28/30\n",
      "33600/33600 [==============================] - 3s 82us/sample - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.0249 - val_accuracy: 0.9951\n",
      "Epoch 29/30\n",
      "33600/33600 [==============================] - 3s 81us/sample - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.0405 - val_accuracy: 0.9927\n",
      "Epoch 30/30\n",
      "33600/33600 [==============================] - 3s 78us/sample - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.0378 - val_accuracy: 0.9927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feb95b14790>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b=cnn_model_b()\n",
    "model_b.fit(x_train, y_train,\n",
    "          batch_size=200,\n",
    "          epochs=30,\n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third model with deep layer(accuracy test=.9939)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 14, 32)        25632     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 226,218\n",
      "Trainable params: 226,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " # Set the CNN model \n",
    " # my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "def cnn_model_c():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation = \"softmax\"))\n",
    "    model.compile( optimizer='adam' , loss = keras.losses.categorical_crossentropy, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "model_c=cnn_model_c()\n",
    "model_c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/50\n",
      "33600/33600 [==============================] - 3s 103us/sample - loss: 1.0091 - accuracy: 0.6508 - val_loss: 0.1462 - val_accuracy: 0.9569\n",
      "Epoch 2/50\n",
      "33600/33600 [==============================] - 2s 74us/sample - loss: 0.1756 - accuracy: 0.9528 - val_loss: 0.1262 - val_accuracy: 0.9646\n",
      "Epoch 3/50\n",
      "33600/33600 [==============================] - 2s 69us/sample - loss: 0.1142 - accuracy: 0.9701 - val_loss: 0.0612 - val_accuracy: 0.9825\n",
      "Epoch 4/50\n",
      "33600/33600 [==============================] - 2s 68us/sample - loss: 0.0881 - accuracy: 0.9769 - val_loss: 0.0613 - val_accuracy: 0.9837\n",
      "Epoch 5/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0682 - accuracy: 0.9815 - val_loss: 0.0590 - val_accuracy: 0.9852\n",
      "Epoch 6/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0585 - accuracy: 0.9854 - val_loss: 0.0433 - val_accuracy: 0.9888\n",
      "Epoch 7/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0553 - accuracy: 0.9843 - val_loss: 0.0496 - val_accuracy: 0.9869\n",
      "Epoch 8/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0488 - accuracy: 0.9873 - val_loss: 0.0373 - val_accuracy: 0.9892\n",
      "Epoch 9/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0444 - accuracy: 0.9880 - val_loss: 0.0423 - val_accuracy: 0.9900\n",
      "Epoch 10/50\n",
      "33600/33600 [==============================] - 2s 68us/sample - loss: 0.0439 - accuracy: 0.9886 - val_loss: 0.0535 - val_accuracy: 0.9863\n",
      "Epoch 11/50\n",
      "33600/33600 [==============================] - 2s 69us/sample - loss: 0.0411 - accuracy: 0.9890 - val_loss: 0.0345 - val_accuracy: 0.9896\n",
      "Epoch 12/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0334 - accuracy: 0.9908 - val_loss: 0.0345 - val_accuracy: 0.9919\n",
      "Epoch 13/50\n",
      "33600/33600 [==============================] - 2s 65us/sample - loss: 0.0310 - accuracy: 0.9914 - val_loss: 0.0335 - val_accuracy: 0.9920\n",
      "Epoch 14/50\n",
      "33600/33600 [==============================] - 2s 65us/sample - loss: 0.0336 - accuracy: 0.9913 - val_loss: 0.0399 - val_accuracy: 0.9918\n",
      "Epoch 15/50\n",
      "33600/33600 [==============================] - 2s 65us/sample - loss: 0.0303 - accuracy: 0.9919 - val_loss: 0.0383 - val_accuracy: 0.9901\n",
      "Epoch 16/50\n",
      "33600/33600 [==============================] - 2s 68us/sample - loss: 0.0251 - accuracy: 0.9931 - val_loss: 0.0317 - val_accuracy: 0.9919\n",
      "Epoch 17/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0307 - accuracy: 0.9914 - val_loss: 0.0410 - val_accuracy: 0.9907\n",
      "Epoch 18/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0255 - accuracy: 0.9929 - val_loss: 0.0374 - val_accuracy: 0.9915\n",
      "Epoch 19/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0276 - accuracy: 0.9927 - val_loss: 0.0316 - val_accuracy: 0.9929\n",
      "Epoch 20/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0252 - accuracy: 0.9928 - val_loss: 0.0355 - val_accuracy: 0.9921\n",
      "Epoch 21/50\n",
      "33600/33600 [==============================] - 2s 67us/sample - loss: 0.0250 - accuracy: 0.9931 - val_loss: 0.0428 - val_accuracy: 0.9914\n",
      "Epoch 22/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0224 - accuracy: 0.9937 - val_loss: 0.0356 - val_accuracy: 0.9927\n",
      "Epoch 23/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0236 - accuracy: 0.9934 - val_loss: 0.0354 - val_accuracy: 0.9931\n",
      "Epoch 24/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0230 - accuracy: 0.9937 - val_loss: 0.0373 - val_accuracy: 0.9913\n",
      "Epoch 25/50\n",
      "33600/33600 [==============================] - 2s 68us/sample - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.0439 - val_accuracy: 0.9898\n",
      "Epoch 26/50\n",
      "33600/33600 [==============================] - 3s 78us/sample - loss: 0.0176 - accuracy: 0.9950 - val_loss: 0.0361 - val_accuracy: 0.9931\n",
      "Epoch 27/50\n",
      "33600/33600 [==============================] - 2s 68us/sample - loss: 0.0191 - accuracy: 0.9946 - val_loss: 0.0294 - val_accuracy: 0.9932\n",
      "Epoch 28/50\n",
      "33600/33600 [==============================] - 2s 70us/sample - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.0393 - val_accuracy: 0.9918\n",
      "Epoch 29/50\n",
      "33600/33600 [==============================] - 2s 67us/sample - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.0333 - val_accuracy: 0.9937\n",
      "Epoch 30/50\n",
      "33600/33600 [==============================] - 2s 67us/sample - loss: 0.0190 - accuracy: 0.9953 - val_loss: 0.0373 - val_accuracy: 0.9925\n",
      "Epoch 31/50\n",
      "33600/33600 [==============================] - 2s 68us/sample - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.0297 - val_accuracy: 0.9925\n",
      "Epoch 32/50\n",
      "33600/33600 [==============================] - 2s 67us/sample - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.0380 - val_accuracy: 0.9929\n",
      "Epoch 33/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0206 - accuracy: 0.9943 - val_loss: 0.0502 - val_accuracy: 0.9888\n",
      "Epoch 34/50\n",
      "33600/33600 [==============================] - 2s 65us/sample - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.0329 - val_accuracy: 0.9929\n",
      "Epoch 35/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0155 - accuracy: 0.9957 - val_loss: 0.0364 - val_accuracy: 0.9937\n",
      "Epoch 36/50\n",
      "33600/33600 [==============================] - 2s 67us/sample - loss: 0.0157 - accuracy: 0.9957 - val_loss: 0.0394 - val_accuracy: 0.9927\n",
      "Epoch 37/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.0425 - val_accuracy: 0.9917\n",
      "Epoch 38/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0145 - accuracy: 0.9961 - val_loss: 0.0326 - val_accuracy: 0.9930\n",
      "Epoch 39/50\n",
      "33600/33600 [==============================] - 2s 68us/sample - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.0433 - val_accuracy: 0.9935\n",
      "Epoch 40/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.0397 - val_accuracy: 0.9929\n",
      "Epoch 41/50\n",
      "33600/33600 [==============================] - 2s 68us/sample - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0409 - val_accuracy: 0.9933\n",
      "Epoch 42/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.0335 - val_accuracy: 0.9944\n",
      "Epoch 43/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.0529 - val_accuracy: 0.9907\n",
      "Epoch 44/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0148 - accuracy: 0.9962 - val_loss: 0.0344 - val_accuracy: 0.9937\n",
      "Epoch 45/50\n",
      "33600/33600 [==============================] - 2s 68us/sample - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.0468 - val_accuracy: 0.9923\n",
      "Epoch 46/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.0368 - val_accuracy: 0.9923\n",
      "Epoch 47/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.0349 - val_accuracy: 0.9933\n",
      "Epoch 48/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.0410 - val_accuracy: 0.9927\n",
      "Epoch 49/50\n",
      "33600/33600 [==============================] - 2s 66us/sample - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.0379 - val_accuracy: 0.9932\n",
      "Epoch 50/50\n",
      "33600/33600 [==============================] - 2s 68us/sample - loss: 0.0142 - accuracy: 0.9962 - val_loss: 0.0354 - val_accuracy: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feb6f13fb50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_c=cnn_model_c()\n",
    "model_c.fit(x_train, y_train,\n",
    "          batch_size=200,\n",
    "          epochs=50,\n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation to prevent overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "#Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=3, #number of epochs with no improvement after which learning rate will be reduced.\n",
    "                                            verbose=1, #Display a message after each epoch\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data first into training and validation dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "random_seed = 2\n",
    "\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(x_train, y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation on model_b (val_accuracy 0.9948)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 756 steps, validate on 4200 samples\n",
      "Epoch 1/40\n",
      "756/756 - 16s - loss: 0.3711 - accuracy: 0.8784 - val_loss: 0.0671 - val_accuracy: 0.9814\n",
      "Epoch 2/40\n",
      "756/756 - 14s - loss: 0.1121 - accuracy: 0.9675 - val_loss: 0.0376 - val_accuracy: 0.9883\n",
      "Epoch 3/40\n",
      "756/756 - 14s - loss: 0.0837 - accuracy: 0.9760 - val_loss: 0.0318 - val_accuracy: 0.9900\n",
      "Epoch 4/40\n",
      "756/756 - 14s - loss: 0.0720 - accuracy: 0.9792 - val_loss: 0.0342 - val_accuracy: 0.9910\n",
      "Epoch 5/40\n",
      "756/756 - 15s - loss: 0.0630 - accuracy: 0.9813 - val_loss: 0.0288 - val_accuracy: 0.9921\n",
      "Epoch 6/40\n",
      "756/756 - 14s - loss: 0.0585 - accuracy: 0.9830 - val_loss: 0.0283 - val_accuracy: 0.9912\n",
      "Epoch 7/40\n",
      "756/756 - 13s - loss: 0.0555 - accuracy: 0.9847 - val_loss: 0.0203 - val_accuracy: 0.9945\n",
      "Epoch 8/40\n",
      "756/756 - 14s - loss: 0.0494 - accuracy: 0.9857 - val_loss: 0.0251 - val_accuracy: 0.9921\n",
      "Epoch 9/40\n",
      "756/756 - 14s - loss: 0.0502 - accuracy: 0.9861 - val_loss: 0.0296 - val_accuracy: 0.9926\n",
      "Epoch 10/40\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "756/756 - 14s - loss: 0.0487 - accuracy: 0.9867 - val_loss: 0.0543 - val_accuracy: 0.9852\n",
      "Epoch 11/40\n",
      "756/756 - 14s - loss: 0.0319 - accuracy: 0.9910 - val_loss: 0.0147 - val_accuracy: 0.9950\n",
      "Epoch 12/40\n",
      "756/756 - 14s - loss: 0.0287 - accuracy: 0.9909 - val_loss: 0.0151 - val_accuracy: 0.9952\n",
      "Epoch 13/40\n",
      "756/756 - 14s - loss: 0.0269 - accuracy: 0.9925 - val_loss: 0.0160 - val_accuracy: 0.9957\n",
      "Epoch 14/40\n",
      "756/756 - 15s - loss: 0.0284 - accuracy: 0.9919 - val_loss: 0.0197 - val_accuracy: 0.9926\n",
      "Epoch 15/40\n",
      "756/756 - 14s - loss: 0.0256 - accuracy: 0.9924 - val_loss: 0.0137 - val_accuracy: 0.9960\n",
      "Epoch 16/40\n",
      "756/756 - 13s - loss: 0.0256 - accuracy: 0.9920 - val_loss: 0.0222 - val_accuracy: 0.9943\n",
      "Epoch 17/40\n",
      "756/756 - 14s - loss: 0.0250 - accuracy: 0.9928 - val_loss: 0.0173 - val_accuracy: 0.9952\n",
      "Epoch 18/40\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "756/756 - 15s - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.0219 - val_accuracy: 0.9940\n",
      "Epoch 19/40\n",
      "756/756 - 14s - loss: 0.0190 - accuracy: 0.9943 - val_loss: 0.0179 - val_accuracy: 0.9952\n",
      "Epoch 20/40\n",
      "756/756 - 13s - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.0143 - val_accuracy: 0.9960\n",
      "Epoch 21/40\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "756/756 - 13s - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.0170 - val_accuracy: 0.9952\n",
      "Epoch 22/40\n",
      "756/756 - 14s - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.0167 - val_accuracy: 0.9955\n",
      "Epoch 23/40\n",
      "756/756 - 14s - loss: 0.0148 - accuracy: 0.9959 - val_loss: 0.0161 - val_accuracy: 0.9955\n",
      "Epoch 24/40\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "756/756 - 14s - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0195 - val_accuracy: 0.9943\n",
      "Epoch 25/40\n",
      "756/756 - 14s - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.0170 - val_accuracy: 0.9955\n",
      "Epoch 26/40\n",
      "756/756 - 14s - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.0174 - val_accuracy: 0.9952\n",
      "Epoch 27/40\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "756/756 - 14s - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0172 - val_accuracy: 0.9955\n",
      "Epoch 28/40\n",
      "756/756 - 13s - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0170 - val_accuracy: 0.9952\n",
      "Epoch 29/40\n",
      "756/756 - 14s - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0178 - val_accuracy: 0.9955\n",
      "Epoch 30/40\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "756/756 - 14s - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.0166 - val_accuracy: 0.9952\n",
      "Epoch 31/40\n",
      "756/756 - 15s - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0171 - val_accuracy: 0.9952\n",
      "Epoch 32/40\n",
      "756/756 - 14s - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.0167 - val_accuracy: 0.9955\n",
      "Epoch 33/40\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "756/756 - 14s - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.0166 - val_accuracy: 0.9957\n",
      "Epoch 34/40\n",
      "756/756 - 14s - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0165 - val_accuracy: 0.9957\n",
      "Epoch 35/40\n",
      "756/756 - 15s - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0166 - val_accuracy: 0.9957\n",
      "Epoch 36/40\n",
      "756/756 - 14s - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0167 - val_accuracy: 0.9957\n",
      "Epoch 37/40\n",
      "756/756 - 14s - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0166 - val_accuracy: 0.9957\n",
      "Epoch 38/40\n",
      "756/756 - 14s - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0163 - val_accuracy: 0.9955\n",
      "Epoch 39/40\n",
      "756/756 - 14s - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.0164 - val_accuracy: 0.9955\n",
      "Epoch 40/40\n",
      "756/756 - 14s - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0158 - val_accuracy: 0.9957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feb48463450>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 40\n",
    "batch_size = 50\n",
    "\n",
    "aug_model_b=cnn_model_b()\n",
    "# Fit the model\n",
    "aug_model_b.fit_generator(datagen.flow(train_x,train_y, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (val_x,val_y),\n",
    "                              verbose = 2, steps_per_epoch=train_x.shape[0] // batch_size,\n",
    "                              callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here We can see that val_accuracy increased on model_b by applying data augmentation. Data augmentation largely reduces Overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_aug_b=predict_model(aug_model_b,x_test)\n",
    "sub_aug_b.to_csv('submission_aug_b.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation on model_c(val_accuracy=.9960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 439 steps, validate on 4200 samples\n",
      "Epoch 1/40\n",
      "439/439 - 13s - loss: 0.7290 - accuracy: 0.7535 - val_loss: 0.1363 - val_accuracy: 0.9576\n",
      "Epoch 2/40\n",
      "439/439 - 12s - loss: 0.1613 - accuracy: 0.9581 - val_loss: 0.0738 - val_accuracy: 0.9826\n",
      "Epoch 3/40\n",
      "439/439 - 12s - loss: 0.1146 - accuracy: 0.9701 - val_loss: 0.0484 - val_accuracy: 0.9869\n",
      "Epoch 4/40\n",
      "439/439 - 13s - loss: 0.0998 - accuracy: 0.9756 - val_loss: 0.0515 - val_accuracy: 0.9864\n",
      "Epoch 5/40\n",
      "439/439 - 13s - loss: 0.0860 - accuracy: 0.9781 - val_loss: 0.0330 - val_accuracy: 0.9898\n",
      "Epoch 6/40\n",
      "439/439 - 12s - loss: 0.0854 - accuracy: 0.9783 - val_loss: 0.0326 - val_accuracy: 0.9900\n",
      "Epoch 7/40\n",
      "439/439 - 12s - loss: 0.0701 - accuracy: 0.9827 - val_loss: 0.0417 - val_accuracy: 0.9893\n",
      "Epoch 8/40\n",
      "439/439 - 13s - loss: 0.0683 - accuracy: 0.9828 - val_loss: 0.0442 - val_accuracy: 0.9910\n",
      "Epoch 9/40\n",
      "439/439 - 13s - loss: 0.0640 - accuracy: 0.9840 - val_loss: 0.0266 - val_accuracy: 0.9936\n",
      "Epoch 10/40\n",
      "439/439 - 12s - loss: 0.0569 - accuracy: 0.9858 - val_loss: 0.0405 - val_accuracy: 0.9926\n",
      "Epoch 11/40\n",
      "439/439 - 12s - loss: 0.0602 - accuracy: 0.9855 - val_loss: 0.0283 - val_accuracy: 0.9943\n",
      "Epoch 12/40\n",
      "439/439 - 12s - loss: 0.0567 - accuracy: 0.9852 - val_loss: 0.0295 - val_accuracy: 0.9917\n",
      "Epoch 13/40\n",
      "439/439 - 13s - loss: 0.0566 - accuracy: 0.9866 - val_loss: 0.0322 - val_accuracy: 0.9914\n",
      "Epoch 14/40\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "439/439 - 13s - loss: 0.0562 - accuracy: 0.9862 - val_loss: 0.0299 - val_accuracy: 0.9936\n",
      "Epoch 15/40\n",
      "439/439 - 12s - loss: 0.0363 - accuracy: 0.9904 - val_loss: 0.0268 - val_accuracy: 0.9940\n",
      "Epoch 16/40\n",
      "439/439 - 12s - loss: 0.0343 - accuracy: 0.9915 - val_loss: 0.0265 - val_accuracy: 0.9950\n",
      "Epoch 17/40\n",
      "439/439 - 12s - loss: 0.0308 - accuracy: 0.9918 - val_loss: 0.0244 - val_accuracy: 0.9948\n",
      "Epoch 18/40\n",
      "439/439 - 13s - loss: 0.0349 - accuracy: 0.9911 - val_loss: 0.0334 - val_accuracy: 0.9945\n",
      "Epoch 19/40\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "439/439 - 13s - loss: 0.0310 - accuracy: 0.9919 - val_loss: 0.0253 - val_accuracy: 0.9950\n",
      "Epoch 20/40\n",
      "439/439 - 12s - loss: 0.0243 - accuracy: 0.9935 - val_loss: 0.0185 - val_accuracy: 0.9952\n",
      "Epoch 21/40\n",
      "439/439 - 13s - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.0175 - val_accuracy: 0.9967\n",
      "Epoch 22/40\n",
      "439/439 - 12s - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.0183 - val_accuracy: 0.9960\n",
      "Epoch 23/40\n",
      "439/439 - 13s - loss: 0.0203 - accuracy: 0.9944 - val_loss: 0.0205 - val_accuracy: 0.9950\n",
      "Epoch 24/40\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "439/439 - 13s - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0151 - val_accuracy: 0.9957\n",
      "Epoch 25/40\n",
      "439/439 - 12s - loss: 0.0183 - accuracy: 0.9956 - val_loss: 0.0204 - val_accuracy: 0.9948\n",
      "Epoch 26/40\n",
      "439/439 - 12s - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.0177 - val_accuracy: 0.9955\n",
      "Epoch 27/40\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "439/439 - 12s - loss: 0.0174 - accuracy: 0.9954 - val_loss: 0.0191 - val_accuracy: 0.9955\n",
      "Epoch 28/40\n",
      "439/439 - 13s - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.0165 - val_accuracy: 0.9950\n",
      "Epoch 29/40\n",
      "439/439 - 13s - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.0205 - val_accuracy: 0.9957\n",
      "Epoch 30/40\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "439/439 - 12s - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.0194 - val_accuracy: 0.9952\n",
      "Epoch 31/40\n",
      "439/439 - 12s - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.0191 - val_accuracy: 0.9955\n",
      "Epoch 32/40\n",
      "439/439 - 12s - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.0181 - val_accuracy: 0.9957\n",
      "Epoch 33/40\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "439/439 - 14s - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.0179 - val_accuracy: 0.9955\n",
      "Epoch 34/40\n",
      "439/439 - 13s - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.0178 - val_accuracy: 0.9952\n",
      "Epoch 35/40\n",
      "439/439 - 13s - loss: 0.0146 - accuracy: 0.9962 - val_loss: 0.0184 - val_accuracy: 0.9952\n",
      "Epoch 36/40\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "439/439 - 12s - loss: 0.0148 - accuracy: 0.9962 - val_loss: 0.0184 - val_accuracy: 0.9952\n",
      "Epoch 37/40\n",
      "439/439 - 13s - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.0186 - val_accuracy: 0.9952\n",
      "Epoch 38/40\n",
      "439/439 - 13s - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.0181 - val_accuracy: 0.9952\n",
      "Epoch 39/40\n",
      "439/439 - 12s - loss: 0.0145 - accuracy: 0.9960 - val_loss: 0.0182 - val_accuracy: 0.9950\n",
      "Epoch 40/40\n",
      "439/439 - 12s - loss: 0.0139 - accuracy: 0.9962 - val_loss: 0.0181 - val_accuracy: 0.9950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe6f007f4d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 40\n",
    "batch_size = 86\n",
    "\n",
    "aug_model_c=cnn_model_c()\n",
    "# Fit the model\n",
    "aug_model_c.fit_generator(datagen.flow(train_x,train_y, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (val_x,val_y),\n",
    "                              verbose = 2, steps_per_epoch=train_x.shape[0] // batch_size,\n",
    "                              callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_aug_c=predict_model(aug_model_c,x_test)\n",
    "sub_aug_c.to_csv('submission_aug_c.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
