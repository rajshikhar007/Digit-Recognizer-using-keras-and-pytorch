{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"#PyTorch Specific libraries\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\n#Data manipulation and visualisation specific libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# For splitting the data into Train and Test set\nfrom sklearn.model_selection import train_test_split\n\n# This piece of code is required to make use of the GPU instead of CPU for faster processing\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\n#If it prints \"cuda:0\" that means it has access to GPU. If it prints out \"cpu\", then it's still running on CPU.\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load the dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n\n#Let's check if they have been loaded properly\nprint('train.shape:\\n', train.shape)\nprint('test.shape:\\n', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.iloc[:,:-1]\nprint('X type', type(X))\n\ny = train.iloc[:,-1:] #Returns a series \nprint('y type', type(y))\ny = train.label.values # it returns np.ndarray, needed for torch tensor conversion\nprint('y type', type(y))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split dataset into train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.1, random_state = 1)\n\nprint('X_train.shape: ', X_train.shape)\nprint('y_train.shape: ', y_train.shape)\nprint('X_test.shape: ', X_test.shape)\nprint('y_test.shape: ', y_test.shape)\nprint(type(X_train))\nprint(type(y_train))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Rescaling values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rescaling values\nX_train = X_train.values/255\nX_test = X_test.values/255","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting to torch tensors"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting to Tensors\nX_train = torch.from_numpy(X_train)\nX_test = torch.from_numpy(X_test)\n\ny_train = torch.from_numpy(y_train).type(torch.LongTensor)\ny_test = torch.from_numpy(y_test).type(torch.LongTensor)\n\nprint('X_train.dtype:', X_train.dtype)\nprint('X_test.dtype:', X_test.dtype)\nprint('y_train.dtype:', y_train.dtype)\nprint('y_test.dtype:', y_test.dtype)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dataset  and DataLoader"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = torch.utils.data.TensorDataset(X_train, y_train)\ntest = torch.utils.data.TensorDataset(X_test, y_test)\n\nbatch = 100\n\n# Set our data loaders\ntrain_loader = torch.utils.data.DataLoader(train, batch_size = batch, shuffle = True)\ntest_loader = torch.utils.data.DataLoader(test, batch_size = batch, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        \n        self.conv1 = nn.Conv2d(1, 128, 5)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.drop1 = nn.Dropout(p=0.3)\n        \n        self.conv2 = nn.Conv2d(128, 224, 5)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.drop2 = nn.Dropout(p=0.4)\n        \n        self.fc3 = nn.Linear(224*4*4, 64)\n        self.drop3 = nn.Dropout(p=0.4)\n        \n        self.fc4 = nn.Linear(64, 32)\n        self.drop4 = nn.Dropout(p=0.4)\n        \n        self.fc5 = nn.Linear(32, 10)\n        self.softmax = nn.Softmax(dim=1)\n   \n    \n    def forward(self, x):\n        x = self.drop1(self.pool1(F.relu(self.conv1(x))))\n        x = self.drop2(self.pool2(F.relu(self.conv2(x))))\n        \n        x = x.view(-1,224*4*4)\n        \n        x = self.drop3(F.relu(self.fc3(x)))\n        x = self.drop4(F.relu(self.fc4(x)))\n        \n        x = self.softmax(self.fc5(x))\n        \n        return x\n\nprint(Net()) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loss function"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making an object of the Net class\nmodel = Net().to(device)\n\n#Loss function\ncriterion = nn.CrossEntropyLoss ()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Optimizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Optimizer\noptimizer = optim.Adam(model.parameters(), lr = 0.0015)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### train the neural network"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialising variables\nepochs = 30\nsteps = 0\nprint_every = 100\ntrainLoss = [] \ntestLoss = []\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for e in range(epochs):\n    running_loss = 0\n    for images, labels in train_loader:\n        steps += 1   # Forward pass\n        \n        images = (images.view(-1,1,28,28)).type(torch.DoubleTensor)\n        optimizer.zero_grad()\n        log_ps = model(images.type(torch.FloatTensor).to(device))\n        labels = labels.to(device)\n        loss = criterion(log_ps, labels)\n        loss.backward()   # Backward pass\n        optimizer.step()\n        \n        running_loss += loss.item()\n        if steps % print_every == 0:\n            test_loss = 0\n            accuracy = 0\n\n            with torch.no_grad():\n                model.eval()\n                for images, labels in test_loader:\n                    images = (images.view(-1,1,28,28)).type(torch.DoubleTensor)\n                    log_ps = model(images.type(torch.FloatTensor).to(device))\n                    labels = labels.to(device)\n                    test_loss += criterion(log_ps, labels)\n                    ps = torch.exp(log_ps)\n                    \n                    top_p, top_class = ps.topk(1, dim = 1)\n                    equals = top_class == labels.view(*top_class.shape)\n                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n\n            model.train()\n\n            trainLoss.append(running_loss/len(train_loader))\n            testLoss.append(test_loss/len(test_loader))\n\n            print(\"Epoch: {}/{}.. \".format(e + 1, epochs),\n                  \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for images, labels in train_loader:\n    print(images)\n    print(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}